{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules and Modularity\n",
    "\n",
    "## Modularity in larger code projects\n",
    "\n",
    "We've already discussed the concept of modularity in programming - the idea that code should be divided into manageable blocks, each of which should ideally perform a single, self-contained task. So far we've applied this concept to group parts of our code into functions, but when we wrote a script in the last lesson, we still kept these functions in the same script as the code that was calling them. This is often completely fine, particularly for small projects - in our case we only had two functions, plus a few lines of other code. But as you try to do more and more with your code, you may quickly find that you end up with dozens of functions, which may perform very different tasks and some of which will likely call others. This situation can be very difficult to manange, especially when you encounter bugs, since following the flow of the code becomes harder the more code you have.\n",
    "\n",
    "We also need to consider how much of our code we will want to re-use later. A very domain-specific function which performs some particular analysis may only be useful for one project, in which case it's perfectly reasonable to define it in the same script as the code that calls it. But many functions are (and should be) much more general than this. A function to calculate the mean of an array, for example, is universal and could be used in any project, so you wouldn't want to have to define one every time you needed it. Of course, we've seen already that such a function exists in NumPy, and this demonstrates how Python allows us to make our codes more modular - by importing code from external scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<section class=\"callout panel panel-warning\">\n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-thumb-tack\"></span> Python and modularity</h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"panel-body\">\n",
    "\n",
    "<p>Like most of the content of this summer school, modularity is a concept which can, and should, be applied to your work no matter what programming language you're using. But one of the reasons this school uses Python - and why it's such a popular choice of language generally - is that the concept of modularity is built into Python at a fundamental level, as we'll explore in this lesson. The core Python language on its own actually doesn't really do very much at all, but being able to import functionality from elsewhere makes it extremely powerful, since it allows you to draw from a large standard library and a vast extended ecosystem of third-party libraries, without forcing you to install anything you don't need.</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "</section>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and modules\n",
    "\n",
    "As noted above, we've already seen some cases of importing in action - for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\- but we haven't really discussed in detail what is actually happening here. In short, Python's `import` statement allows you to fetch the contents of another Python script. So in your script (or in the notebook), when you run the command above, Python goes and finds the file it associates with the name `numpy`, runs that file and creates a variable `np` in your code which contains the variables and functions defined in that file.\n",
    "\n",
    "For installed packages like `numpy`, there the installation process places the scripts needed for each package in a folder somewhere on your computer and tells Python where it can access them. But it also works on a smaller scale - the `import` statement can also import any arbitrary script from within the same folder, by specifying the name of that file without the `.py` extension.\n",
    "\n",
    "To demonstrate how this can be useful for you in your research, let's go back to the script we wrote in the last lesson, `rcsc18-data-analysis.py`. Copy the functions defined in that file and put them into a new file called `analysis_tools.py`. Also copy the import statements for NumPy and matplotlib, as the functions require these to run correctly. Then save and close the new file. Make sure both files are located in this folder.\n",
    "\n",
    "Now that we have a separate file which defines the functions for our analysis, we can import that just like the installed libraries we've used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse(filename):\n",
    "    \"\"\"\n",
    "    Reads data from the specified file and plots the average, maximum and minimum along the first axis of the\n",
    "data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Name or path to a file containing data to be plotted. Data should be 2-dimensional and values should be\n",
    "        separated by commas.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> analyse('/path/to/mydata.dat')\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    fig = plt.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "    axes1 = fig.add_subplot(1, 3, 1)\n",
    "    axes2 = fig.add_subplot(1, 3, 2)\n",
    "    axes3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "    axes1.set_ylabel('average')\n",
    "    axes1.plot(np.mean(data, axis=0))\n",
    "\n",
    "    axes2.set_ylabel('max')\n",
    "    axes2.plot(np.max(data, axis=0))\n",
    "\n",
    "    axes3.set_ylabel('min')\n",
    "    axes3.plot(np.min(data, axis=0))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def detect_problems(filename):\n",
    "    \"\"\"\n",
    "    Tests data stored in the specified file for spurious or unexpected values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Name or path to a file containing data to tested. Data should be 2-dimensional and values should be\n",
    "        separated by commas.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> analyse('/path/to/mydata.dat')\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    if np.max(data, axis=0)[0] == 0 and np.max(data, axis=0)[20] == 20:\n",
    "        print('Suspicious looking maxima!')\n",
    "    elif np.sum(np.min(data, axis=0)) == 0:\n",
    "        print('Minima add up to zero!')\n",
    "    else:\n",
    "        print('Seems OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can interact with the functions we've defined there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function detect_problems in module analysis_tools:\n",
      "\n",
      "detect_problems(filename)\n",
      "    Tests data stored in the specified file for spurious or unexpected values.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : str\n",
      "        Name or path to a file containing data to tested. Data should be 2-dimensional and values should be\n",
      "        separated by commas.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> analyse('/path/to/mydata.dat')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(analysis_tools.detect_problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see this setup works in the notebook, but it's supposed to help us with our analysis script, so let's go back to that. Open your script, `rcsc18-data-analysis.py` and delete the functions defined there if you haven't already - you won't need them here since they're being defined elsewhere and imported. Then, add `import analysis_tools` to the top of the script with the other import statements (you can also remove the imports for packages used in the functions, since these are no longer required in this script). Finally, you will need to change your function calls so that they use the functions from the imported file, like we've done above - otherwise your script will not be able to find these functions. After these changes, your analysis script should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you run this script in the command line with `python rcsc18-data-analysis.py`, it should behave exactly as it did when you ran it in the last lesson. We haven't changed any of the code, only rearranged it, in the same way as when we moved parts of the code into functions earlier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
